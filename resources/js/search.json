[[{"i":"what-is-ezkl","l":"What is EZKL?"},{"l":"EZKL makes zero-knowledge easier","p":["ezkl takes a high-level description of your program and sets up a zero-knowledge prover and verifier. Our focus is on programs that are expressed as pytorch AI/ML models and other computational graphs. After setup, the prover can prove statements such as the following.","\"I ran this publicly available neural network on some private data and it produced this output\"","\"I ran my private neural network on some public data and it produced this output\"","\"I correctly ran this publicly available neural network on some public data and it produced this output\"","These proofs can be trusted by anyone with a copy of the verifier, and verified directly on Ethereum and compatible chains. ezkl can be used directly from Python; see this colab notebook and the python bindings docs. It can also be used from the command line.","ezkl can prove an MNIST-sized inference in less than a second and under 180mb of memory and verify it on the Ethereum Virtual Machine (or on the command line, or in the browser using wasm).","You can install the Python version with pip install ezkl.","ezkl can be used to move large and complex computations off-chain in a way that is easy to program (you can write your own functions in Python) and manage. You are not limited to a pre-defined set of functions, there is no limit on input size (using hashing), and there is no centralized sequencer.","For more details on how to use ezkl, we invite you to explore the docs and check out the repo, especially the notebooks."]},{"i":"proving-backend-lilith","l":"Proving Backend (Lilith)","p":["Running ZKML proofs can be computationally expensive. We've made the process easier by providing a backend service that can run the proofs for you.","If you're interested in using the Lilith backend, you can register your interest here."]},{"l":"The life cycle of a proof","p":["There are three steps in the life of an ezkl proof: Setup, Prove, and Verify. Each step is generally performed by a different party."]},{"l":"Setup","p":["Setup is invoked with ezkl setup at the cli or ezkl.setup() in Python. It defines what constitutes a proof and how that proof will be verified, setting the rules of the game. Setup is performed by the application developer, who then deploys the resulting artifacts to production.","The inputs to setup are:","the model (as an onnx file)","the structured reference string which is a common, public piece of cryptographic data shared among proof setups of the same size","various flags, settings, and options for tuning and added functionality","The outputs of setup are:","the proving key","the verification key, and","the circuit settings: serialized flags, settings, and options, and a few numbers that describe the shape of the resulting circuit.","Before setup can run, the settings need to be generated with gen-settings and optionally calibrate-settings, and the model must be compiled."]},{"l":"Prove","p":["Prove, invoked with ezkl prove at the cli or ezkl.prove() in Python, is called by the prover, often on the client. The prover is making a claim that it knows some inputs (which might include model parameters), such that when the model (chosen during setup) is run on them, produces certain outputs. The prove command computes a cryptographic proof of that claim, which can then be believed by any verifier.","The inputs to prove are:","the witness data for the claim: an (input, output) pair (x,y) such that model(input) = output (this pair can be produced from x using the gen-witness command)","the model (as a compiled model file, made from an onnx file)","the proving key","the structured reference string, and","the circuit settings.","The outputs of prove are:","the proof file."]},{"l":"Verify","p":["ezkl can produce an EVM verifier contract which takes only the proof as input, and this is the normal use case.","Verification can also be invoked with ezkl verify at the cli, ezkl.verify() in Python, or with WASM. It checks the correctness of the cryptographic proof produced by the prover.","The inputs to (non-EVM) verify are:","the proof file","the verification key","the circuit settings, and","the structured reference string"]},{"i":"contributing","l":"Contributing \uD83C\uDF0E","p":["If you're interested in contributing and are unsure where to start, reach out to one of the maintainers on our Telegram group or our Discord.","More broadly:","Feel free to open up a discussion topic to ask questions.","See currently open issues for ideas on how to contribute.","For PRs we use the conventional commits naming convention."]}],[{"l":"Installing"},{"l":"Installing EZKL","p":["To use ezkl in Python, just pip install ezkl. You will generally also need onnx installed if you are exporting models, and Pytorch, Tensorflow, or similar if you are creating models.","ezkl uses your system solc Solidity compiler, so you may need to tweak it using svm-rs or solc-select, particularly if you are targeting a specific hardfork.","To use the cli, download a release binary from GitHub. If you want the latest build, you can also install from source."]},{"i":"building-from-source","l":"Building from source \uD83D\uDD28","p":["Ezkl is built in rust. First install rust, then download the repo and enter the directory","After which you may build and install the library","If you want to build manually with cargo build, be sure to use the release flag as the debug build will result in slow proofs","You can always check the options available for a command by typing the command with --help. For example, ezkl table will show you the options available for the table command. This will provide you with the most up-to-date information on a given command's usage and the cli spec.","Note: To render your model circuits, you'll need to compile ezkl with the render feature ( cargo build --features render --bin ezkl). This enables the render-circuit command which can create .png representations of the compiled circuits. You'll also need to install the libexpat1-dev and libfreetype6-dev libraries on Debian systems (there are equivalents for MacOS as well)."]},{"i":"rust-docs","l":"Rust docs \uD83D\uDCD6","p":["Use cargo doc --open to compile and open the Rust documentation for ezkl in your default browser."]}],[{"l":"Getting Started"},{"i":"tutorial","l":"Tutorial \uD83D\uDC7E","p":["You can easily create an .onnx file using pytorch. For samples of Onnx files see here. To see how to generate Onnx files using python, check out the notebooks.. You'll also need an input.json file with sample inputs and outputs of your model.","Sample onnx files are also available in the repo ."]},{"l":"Initializing the project","p":["To generate a proof on one of the examples, first install ezkl Getting Started","Put a model file ( network.onnx) and input file ( input.json) into your working directory, e.g. with something like:","(You can get these specific files from this directory.)","To display ezkl's understanding of the model in the CLI, run:","You can always check the options available for a command by typing the command with --help. For example, ezkl table --help will show you the options available for the table command. This will provide you with the most up-to-date information on a given command's usage and the cli spec."]},{"i":"proving-backend-lilith","l":"Proving Backend (Lilith)","p":["Running ZKML proofs can be computationally expensive. We've made the process easier by providing a backend service that can run the proofs for you.","If you're interested in using the Lilith backend, you can register your interest here."]},{"l":"Setting circuit parameters","p":["Our circuit is configured with the settings.json file. This is created with the gen-settings command.","This will produce a settings.json file you can use for your circuit. However, you can fine-tune your circuit to optimize for accuracy or CPU/memory usage with the calibrate-settings command:","In this example, we set the --target to \"resources\" so that we can optimize for CPU and memory usage. The other option is \"accuracy\", which optimizes for accuracy given the fixed point representation of the input model. Our circuit parameters are generated, then saved to settings.json.","Download the appropriate SRS locally.","From the network.onnx onnx file, we will create a settings.json file that uses the py_run_args file to specify the visibility of the inputs, outputs and paramaters of the model.","Once we have created the settings file, we can calibrate it using the ezkl.calibrate_settings command to optimize for either accuracy or resources using the input to the model ( input.json), and the model itself ( network.onnx). The accurary target will optimize the circuit for accuracy given the fixed point representation of the input model. The resources target will optimize the circuit for CPU and memory usage.","Check out this colab notebook for more context around this code snippet.","For performance reasons, you can only generate settings using the hub, python and cli environments. Stay tuned for updates!"]},{"l":"Compiling the model","p":["From the onnx file, we will create a .ezkl file that uses the settings to convert the onnx model to a format ready for proving.","From the network.onnx onnx file, we will create a network.compiled file that uses the settings.json file to convert the onnx model to a format ready for proving. Check out this colab notebook for more context around this code snippet.","For performance reasons, you can only compile ONNX models using Lilith, python and cli environments. Stay tuned for updates!"]},{"l":"Creating the circuit","p":["Now, we use setup to create a proving and verifying key for our circuit, using the SRS and our compiled .ezkl onnx model.","This creates the verification key, proving key, and circuit settings in the locations you specify.","Note: The when using ezkl get-srs, the file is stored in $HOME/.ezkl/srs. You will need to locate it, and change the path/name as appropriate in the command above.","Note: You can view the options associated to a subcommand such as setup by typing ezkl setup with no parameters. If you provide some but not all required parameters, ezkl will tell you what else it needs.","From the compiled model and SRS (structured reference string), we will setup the circuit parameters consisting of the proving and verifying keys. Check out this colab notebook for more context around this code snippet.","The EZKL Engine npm package supports the setup command. Though we do not recommend it. We recommend using Lilith, python or cli environments for performance reasons. Stay tuned for updates!","==="]},{"l":"Making a proof","p":["First we generate a witness file.","Next we will generate a proof that the model was correctly run on private inputs (this is the default setting)..","To generate a proof, we first need to make a witness file. We can do this by running a forward pass using the input data on the compiled model.","We can use this witness, along with the compiled model, proving key and SRS to generate a proof that the model was correctly run on public inputs.","Check out this colab notebook for more context around this code snippet.","Generate a witness file using the form rendered below.","View Source Code","Use the form rendered below to generate ZKML proofs in the browser right now :)"]},{"l":"Verification","p":["We can then verify our generated proof with the verify command:","Using the proof, settings, verification key and SRS, we can verify our proof.","Check out this colab notebook for more context around this code snippet.","Use the form rendered below to verify ZKML proofs in the browser right now :)","View Source Code"]}],[{"l":"Verifying On-Chain"},{"i":"verifying-with-the-evm-","l":"Verifying with the EVM ◊","p":["To verify on-chain, generate a verifier smart contract after performing setup.","You can use the example from Commands, or create it by copying over a network and input file (assuming the ezkl repo is in your home directory):","then create the setup","Now we use this setup to create an EVM verifier, which would be deployed on-chain.","Note: Due to the introduction of PUSH0 opcode in post-Shangai network, only contracts compiled with solc >= 0.8.20 end up using that opcode. If you want to deploy to a pre-Shangai network (which includes nearly all of the most popular L2s at the time of writing), you need to use solc 0.8.19 or earlier.","Note that the .sol file above can be deployed and composed with other Solidity contracts, via a verify() function."]},{"l":"Aggregation","p":["Note: this is an advanced technique, very resource-intensive, and chances are you don't want to use this; if you are having trouble with proof size, first try asking about your problem in Telegram or Discord.","The above pipeline can also be run using proof aggregation to reduce the final proof size and the size and execution cost of the on-chain verifier. A sample pipeline for doing so would be as follows.","Grab a smaller model.","Set up the first proof.","Setup the aggregate proof.","Also note that this may require a local solc installation. You can follow the SolidityLang instructions linked above, or you can use svm-rs to install solc. Here's how:","Install svm-rs:","Install a recent Solidity version (we use 0.8.20 in our implementation):","Verify your Solidity version:"]}],[{"i":"visibility-what-is-private","l":"Visibility: What is Private?"},{"l":"Visibility","p":["In ezkl there are four choices for Visibility: private, public, hashed, or encrypted, and three parts to chose these for: the model input, the model weights, and the model output (for 64 possible choices). The default setting is private input, public output, and private weights.","Visibility is controlled in the circuit settings ( settings.json file), and is determined at setup time.","The question of what is private is very much related to the question of what we are proving. These questions tend to be a bit subtle and are really about designing the overall cryptosystem, of which your ezkl proof is a part. We provide these options to enable many different constructions. It can take some thought to determine which is right for your use case.","At a high level, mark those things private that you want to be secret to the prover, and allow the prover to change freely. Mark things public if you want them to be baked into the setup, and generally available (although see the comments about weight visibility below). Setting a part to hashed is a way to commit to it, and also a way to build bridges between proofs, making sure that a piece of data (input, weights, or output) is the same in multiple proofs. Hashed parts are also useful to reduce calldata size for smart contracts, and to allow something to be signed. Finally, setting a part to kzgcommit is a way to commit to it, and also a way to build bridges between proofs, making sure that a piece of data (input, weights, or output) is the same in multiple proofs.","Note that the proof file contains both the instance data (e.g. a hash of the model input and the actual output of the model) and the bytes of the cryptographic proof. These parts (instance data, proof bytes) are analogous to the message hash and signature in a digital signature."]},{"i":"data-provenance-signatures-and-linking-data","l":"Data provenance, signatures, and linking data","p":["A digital signature is a kind of zero knowledge proof. Ezkl can prove that a certain model says an image contains a cat, but you also have to think about whether that image is real (if that is important for your application). One technique to solve this data provenance problem is to use hashed visibility for the input image, and have a data source which separately signs the hash. Then the verifier can check the signature separately.","Putting it together, you would have two proofs. One, that Alice signed the (hash of the) image, using any signature algorithm on the Poseidon hash of the image. This can be computed and verified outside ezkl. Two, that the image with the given Poseidon hash contains a picture of a cat.","Then a verifier or verifier contract checks both the signature and the ezkl proof, and since the hash is the same, can be confident that the signature and the proof are \"talking about\" the same image."]},{"l":"Weight visibility","p":["When a model's weights are marked fixed, the weights are fixed at setup (circuit definition time). These weights are extractable from the proving key or the onnx file, but they can be kept private from the verifier as they are not part of the verifying key, proof, settings, or srs. Proofs can only be produced against the specific weights used at setup, so the verifier itself serves as a kind of implicit commitment to the weights. If you want to make an explicit commitment to the weights, for example to tie them to another model or sign them, use the hashed or kzgcommit visibility.","Private: The weights are private to the prover, and can be chosen freely by the prover.","Fixed: The weights are fixed by the setup, fully visible in the proving key, and only committed to in the verifying key or verifier (although be aware of dictionary attacks).","Hashed: The weights are private, but the hash of the weights is in the proof file, preventing the prover from changing the weights.","KZGCommit: The kzg commitments to the weights are in the proof file, preventing the prover from changing the weights."]},{"l":"Input visibility","p":["Private: The input is private to the prover, and can be chosen freely by the prover.","Public: The input is part of the proof file, shared with the verifier.","Fixed: The input is fixed by the setup, fully visible in the proving key, and only committed to in the verifying key or verifier (although be aware of dictionary attacks).","Hashed: The input is not sent in the proof file, but a Poseidon hash of the input is sent instead. The input is chosen by the prover, but it has to match the hash. The verifier cannot determine the input from the hash alone (although beware of dictionary attacks).","KZGCommit: The kzg commitment to the input is in the proof file, preventing the prover from changing the input."]},{"l":"Output visibility","p":["Private: The model output is private to the prover, and can be chosen freely by the prover.","Public: The model output is part of the proof file, shared with the verifier.","Fixed: The model output is fixed by the setup, fully visible in the proving key, and only committed to in the verifying key or verifier (although be aware of dictionary attacks).","Hashed: The model output is not sent in the proof file, but a Poseidon hash of the output is sent instead. The verifier cannot determine the output from the hash alone (although beware of dictionary attacks).","KZGCommit: The kzg commitment to the output is in the proof file, preventing the prover from changing the input."]},{"l":"Visibility Examples","p":["This section can safely be skipped but might provide more clarity on some common options for visibility. Consider a function f which given inputs x,y and weight c computes f(x,y) = cx+y.","Notice that weights \" c\" are different from the inputs x,y and output z. Weights are defined as part of the model (and will appear in the onnx).","Suppose we set input public, weights fixed (\"public\"), and output public. This means that c will be baked into the verifier and cannot be changed for this verifier. The witness data that will become part of the proof is (x,y,z). The prover is proving that cx+y = z, and the verifier sees x,y, and z, but not c. The setter-upper and the prover know c.","If we set input private, weights fixed (\"public\"), and output public, the witness data in the proof is (z). The prover is proving that it knows secret x,y such that cx+y = z. The setter-upper and the prover know c; the prover knows x,y; the verifier learns only z.","If we set input private, weights private, and output public, the witness data in the proof is (z). The prover is proving that it knows secret x,y,c such that cx+y = z(practically the prover might set c by changing a provided onnx file). The setter-upper does not know c, the prover knows c,x,y. The verifier learns only z.","If we set input private, weights hashed ( h = H(c)), and output public, the witness data in the proof is (h,z). The prover is proving that it knows secret x,y,c such that cx+y = z and h=H(c). The setter-upper does not know c, the prover knows c,x,y. The verifier learns only z and h. However, if h was previously committed to, the prover can no longer freely choose the weight c.","Hashed weights and fixed (\"public\") weights are similar in that they both constrain the weights that the prover can use. They differ in that fixed weights bake the weights into the circuit at setup, whereas hashed weights can be determined at proof time. One consequence is that for fixed weights, to change the weights a new verifier would need to be deployed, whereas for hashed weights we could simply require a different hash target. However, we pay a performance penalty for the flexiblity of using the \"dynamic\" hashed weights rather than the \"compiled\" fixed weights."]}],[{"l":"Engine"},{"l":"Installation","p":["As well as some helper functions that make formatting data to and from field elements (the way numbers are represented in ZK):","bufferToVecOfVecU64: Converts a buffer to vector of vector of 4 u64s","deserialize: Convert the serialized representation of a given artifact into a JS object.","elgamalDecrypt: Decrypt a cipher text using the ElGamal secret key","elgamalEncrypt: Encypt an arbitrary message using the ElGamal public key and randomness.","elgamalEncrypt.test.ts","elgamalGenRandom: Generate an ElGamal keypair from a random seed.","fieldElementUtils.test.ts","floatToVecU64: Converts a floating point element to 4 u64s representing a fixed point field element","genWitness: Generate a witness from a given input.","If you want to get your hands dirty with the Engine bindings, check out this github codespace: Open in GitHub Codespaces It contains descriptive Jest tests that show you how to use the various bindings available in @ezkljs/engine/nodejs package as well as an example Next.js application that demos the @ezkljs/engine/web web bundle. Simply run pnpm run test to execute all of the tests in the codespace. Everything should work out of the box, no setup commands necessary.","poseidonHash: Hash a given message using the Poseidon hash function","poseidonHash.test.ts","prove: Generate a proof","proveVerify.test.ts","serialize: Convert the JS object representation of a given artifact into a format that can be accepted by the engine methods.","The engine exposes JS bindings to the main ezkl repo that make hashing, encrypting, decrypting, proving and verifying in the browser/nodejs context seamless:","The engine methods use web assembly in the backend to support running rust code in a browser/JS context. Non primitive data types passed to and returned from WASM bindings must come in a serialized (buffer) format. These serialize and deserialize methods make it easier to convert JS objects to and from a format that can be accepted by the engine methods.","To install EZKL engine, simply use your favorite package manager:","To spin up the example web app locally run pnpm run dev","To view each test, open the tests directory and click on the test you want to view. All of them are written in typescript and are well documented.","vecU64ToFelt: Converts 4 u64s to a field element (hex string)","vecU64ToFloat: Converts 4 u64s representing a field element directly to a (rescaled from fixed point scaling) floating point","vecU64ToInt: Converts 4 u64s representing a field element directly to an integer","verify: Verify a given proof","We have broken down the tests for the bindings into 4 different files:"]},{"l":"Nodejs vs Web targets","p":["The engine has two targets: nodejs and web. The nodejs target is used for nodejs applications (e.i. nodejs serverside data processing) and the web target is used for browser applications (e.i. React front ends). From a peformance standpoint, the only difference between the two is that the web bundle supports multithreading via a web worker instance and nodejs does not.","This readme will focus on documenting the web target. If you are interested in using the nodejs target, please refer to the unit tests we wrote for them.","If you just want to jump right into viewing an example application that demonstrates how to use all of the core engine bindings check out this app. The code for which can be found here"]},{"i":"cross-origin-isolation-very-important","l":"Cross Origin Isolation [VERY IMPORTANT].","p":["In order to use \"SharedArrayBuffer\" feature in all browsers, you need to ensure the global crossOriginIsolated is set to true. Otherwise, the ezkljs engine bindings might not work across all browsers, as the WebAssembly memory is shared between the main thread and the web worker. Follow this guide by Google to ensure your web app is cross origin isolated. In the example app we built using next js, we enabled cross origin isolation by adding the following to our next.config.js file:"]},{"l":"Engine Debugging","p":["To make the errors returned by the engine comprehenadble, we recommend calling the init_panic_hook method before calling any of the other engine methods. This will ensure that the engine errors are logged to the console in a readable format, otherwise if an error does throw it will be logged to the console as RuntimeError: unreachable","If you also want to print debug statments from the engine, you can call the init_logger method. This will print all debug statments to the console."]},{"i":"instantiating-a-new-web-assembly-instance","l":"Instantiating a new web assembly instance.","p":["If you are using the web bundle, you will first need to initialize a web assembly module before you can use any of the methods exposed by the engine. To do this import the default export from @ezkljs/engine/web/ezkl.js and then call it. If you want to overide the default WASM memory size, you can pass in a WebAssembly.Memory object as the second argument. We highly recommend doing this if you want your application to be compatible with mobile browsers, as the default memory allocation is too large for iOS browsers. From our experimentation, we have found that the maximum memory allocation that iOS browsers can handle is 4096 mb (default is 65536 mb).","In the example code below, we call each of these potential \"setup\" methods in the useEffect hook of the home component of a Next.js application::"]},{"l":"Generating a witness","p":["Check out the generate witness form in the example app here. To generate a witness from a given input, you can use the genWitness method. You can think of the witness as the input output pair that gets generated by quantizing the input, running it through the quantized model and performing any hashing or encryption. This witness file contains the input and output pair needed to prove statements such as \"I ran my neural network on this data and it produced this output\". Link to the method used here in the example app: handleGenWitnessButton.","Output:"]},{"l":"Elgamal Variables","p":["Check out the encryption form in the example app here. You can generate a random ElGamal keypair from a random seed to use for encryption and decryption by using the elgamalGenRandom method. Link to the methods used here in the example app: handleGenREVButton","Output:"]},{"l":"Elgamal Encrypt","p":["Check out the encryption form in the example app here. Using the public key (pk) and randomness (r) from the previous step, you can encrypt an arbitrary message using the elgamalEncrypt method.","In the example app we use this ElgamalZipFileDownload method to download the r, sk and pk fields of the elgamalVariables as JSON files.","Once you have downloaded your Elgamal variables by clicking the \"Generate\" button at the top of the page, you can unzip the \"elgamal_var\" file in your download folder.","After which you need to create a text file that contains a message you wish to encrypt. Since elgamal encrypt is a ZKP operation, we need to convert the message into serialized field elements represented as u254s. We serialize the field elements by breaking up each u254 field element into 4 u64s.","For reference, check out the example message file here","Output:"]},{"l":"Elgamal Decrypt","p":["Check out the encryption form in the example app here. Using the secret key (sk) and ciphertext from the previous step, you can decrypt the ciphertext using the elgamalDecrypt method. Method used in the example app: handleGenElgamalDecryptionButton","Output:","And as you can see, the output matches the original message inside of message.txt that we encrypted :-)"]},{"l":"Prove","p":["Check out the proving form in the example app here. Once you have all the necessary artifacts needed to prove (Witness, Proving Key, Compiled Onnx Model and SRS) you can generate a proof using the prove method. Method use in the example app handleGenProofButton","Output:"]},{"l":"Verify","p":["Check out the verifying form in the example app here. When the proof has been generated, you can verify it using the verify method. In addition to the proof, you will need to pass the file contents of the verification key, circuit settings and srs files. If all the artifacts are correct, the verify method will return true. The method used in the example app: handleVerifyButton","Output:"]},{"l":"Hash","p":["Check out the hashing form in the example app here. We can also use the engine to hash a given message using the Poseidon hash function. Like with the elgamal encryption and decryption, we need to convert the message into serialized field elements.","If you use the same message.txt file from the elgamal encryption example, you should get the following output:"]}],[{"l":"Verify","p":["EZKL Verify enables in-browser evm verification of EZKL proofs.","Open up the @ezkljs/verify codespace: Open in GitHub Codespaces then run pnpm run test in the provided terminal to execute the jest tests on the library."]},{"l":"Motivation","p":["We would like the Solidity verifier to be canonical and usually all you ever need. For this, we need to be able to run that verifier in browser, using a lightweight EVM implementation, ethereumjs."]},{"l":"Usage","p":["@ezkljs/verify provides the localEVMVerify function which spins up an ephemeral EVM instance for executing the bytecode of a solidity verifier."]},{"l":"localEVMVerify","p":["Parameters:","[proof] (Uint8Array | Uint8ClampedArray): The proof to be verified in serialized format.","[bytecode] (string): The bytecode of the compiled Solidity verifier represented as a string.","[evmVersion] (Hardfork [optional]): The Ethereum hardfork version target for the compiled bytecode. Default is Hardfork.London.","Return Value:","A Promise that resolves to a boolean indicating whether the verification succeeded."]},{"l":"Example","p":["Check out how the ezkljs verify library is used in the ezkljs web app Link to the method used here in the example app: handleEvmVerifyButton","Output:"]}],[{"l":"Python bindings"},{"l":"using ezkl from Python","p":["lets you use ezkl directly from Python. Here is a colab notebook that shows how to produce and verify a proof from Python.","When installing ezkl with pip, you may want to use a virtualenv. Some virtualenv management solutions for python includes venv, pipenv, conda, and poetry."]},{"l":"development","p":["Python bindings are built for ezkl using PyO3 and Maturin.","To test the development Python bindings you will need to install Python3.","Note, ezkl is only supported for Python=3.7."]},{"l":"2. Install solc-select or svm-rs","p":["To run solidity and evm related functionality make sure to have solc available in your environment. We will need solc = 0.8.20, otherwise contracts will fail to compile. Otherwise, you are likely to encounter errors when dealing with solidity and evm related functionality that is used within ezkl.","It is recommended that you use solc-select if you prefer a python based management solution or svm if you prefer a rust based management solution. With a solidity version manager you are then able to change solidity versions in your environment easily."]},{"l":"3. Try out EZKL Examples in the repository with a Jupyter Notebook","p":["Clone the pyezkl repository.","Install jupyter and start the jupyter notebook","Navigate to the ezkl_demo.ipynb file which is located in the examples folder. It contains a minimal setup for running ezkl within python."]},{"l":"Developmental python bindings","p":["Setting up the development python bindings can be an involved process."]},{"l":"ezkl repository","p":["In the event that you may want to use the developmental bindings on the main ezkl repository, you can clone and build the main ezkl repository written in rust instead.","It's recommended that you set up a separate virtual environment for this.","Ensure that rust is installed in your local environment, this is needed by maturin/pyo3 to build the project.","Change the default toolchain to the nightly version as this is needed by some of the libraries used.","After which, you should be able to build via maturin build. This will build ezkl_lib not ezkl. ezkl_lib only includes the basic rust bindings without other Python functionality."]},{"l":"API Reference","p":["This reference details function, modules, and objects included in both ezkl.","You can find the full api reference here."]}],[{"l":"Library"},{"l":"Talks to watch","p":["Dante and Jason - Zero-Knowledge Machine Learning with EZKL in Autonomous Worlds","Jason Morton - What Is Unlocked by Practical Zero-Knowledge Proofs? | EDCON 2023 Montenegro","Zuzalu ZKML 101 and panel.","Empower - coming soon","ETH Denver talks - coming soon","Jason Morton - Zero-Knowledge Machine Learning 6 Jan 2023 | ZK SYMPOSIUM","Jason Morton - Zero-Knowledge Machine Learning 16 Nov 2022 | ZkProof Tel Aviv","Jason Morton - Zero-Knowledge Machine Learning 15 Sep 2022 | DEVCON Bogota","Jason Morton - Zero-Knowledge Machine Learning | Stanford Science of Blockchain Conference 2 Sept 2022"]},{"l":"Blog posts","p":["Constraint efficiency","Snarking a GPT"]},{"l":"EZKL in the press and blogs","p":["Spectral Finance: The State of Zero-Knowledge Machine Learning (zkML), 6 June 2023","Fortune: A brief history of zero-knowledge proofs, the buzzy mathematical technique that’s taken crypto by storm, 5 June 2023","1kx: zkML: Evolving the Intelligence of Smart Contracts Through Zero-Knowledge Cryptography, 23 May 2023","Fortune, 4 May 2023","a16z: Checks and balances: Machine learning and zero-knowledge proofs, 5 Apr 2023","SevenX Ventures: Balancing the Power of AI/ML: The Role of ZK and Blockchain","Coincu: ZKML: Breakthrough Technology With Growth Potential In Security Application","Worldcoin: An introduction to zero-knowledge machine learning (ZKML) 22 Feb 2023"]}],[{"l":"Security","p":["Zero knowledge machine learning, particularly in blockchain applications, is still a nascent field and should be used with caution. Because there have not yet been many production-ready projects, the potential attack vectors include both the usual and the mostly theoretical or unknown. ezkl has not been audited and we make no guarantees on its security.","Moreover, zkml is just one component of an overall cryptosystem, and that system as a whole has to be carefully thought out. Neural networks are not by themselves adequate hash functions; the whole point is that they are susceptible to differentiation!","Here are a few more things to worry about."]},{"i":"aiml-security","l":"AI/ML Security","p":["There are several types of adversarial attacks on neural networks. Gaussian Noise Injection, Data poisoning, Membership Inference Attacks(MIAs), and more are attack vectors that adversaries can use to corrupt your outputs. MIAs and others like it are especially hazardous when the aim of using zkml is to keep the model and its training data private.","Adversarial Training involves training your model with adversarial data so that edge cases are expected and accounted for. CleverHans is a useful tool for discovering potential vulnerabilities in your model. For best security results, have an idea of the overall threat model of your neural net and its potential inputs."]},{"l":"ZK Security","p":["The goal of zero knowledge proof systems is to construct complete, sound proofs. Completeness is the highly probable assurance that any valid proof will verify. Soundness is the quality of the verifier (or parties representing the verifier) knowing that if a proof passes, it is more than likely a true statement. In some cases, such as those in underconstrained circuits, bad proofs can be generated that fool the verifier into passing a false statement. In this case, the vulnerability is not in the machine learning model itself, but in the SNARK constructed by ezkl.","ezkl is a compiler, so eventually should be less susceptible to such issues than a hand-written circuit, but it is still under active development.","Please reach out directly to let us know of any soundess issues you encounter."]},{"l":"Fuzzing","p":["ezkl supports fuzzing over your model's edge inputs to test for potential vulnerabilities. Use your input.json and network.onnx files to run:","Be sure to replace num-runs with the amount of fuzz testing rounds you want to do along with other parameters you are using to generate your circuit.","Thank you for using ezkl; please contact us if you have any comments on this documentation."]}],[{"l":"FAQ"},{"i":"what-programming-languages-and-frameworks-does-ezkl-support","l":"What programming languages and frameworks does ezkl support?","p":["ezkl is a command line tool, and a library that can be used from Rust or Python. You may want to use Python to create a neural network and export it. Though ezkl is built with Rust, you do not need to use Rust except possibly for installation."]},{"i":"do-i-need-to-know-rust-before-getting-started-with-ezkl","l":"Do I need to know Rust before getting started with ezkl?","p":["No, Rust is not a requirement to use the library. As long as you have the ONNX file and proper input & output format of the model, you can use ezkl."]},{"l":"Technical"},{"i":"why-is-the-gen-srs-step-slow","l":"Why is the gen-srs step slow?","p":["Generating a structured reference string takes a considerable amount of time and memory. Make sure your machine has enough memory available and wait for the process to finish. Alternatively, download a pre-generated srs using get-srs. This is both safer and faster."]},{"i":"can-i-use-ezkl-with-other-machine-learning-frameworks-like-tensorflow-pytorch-or-scikit-learn","l":"Can I use ezkl with other machine learning frameworks like TensorFlow, PyTorch, or Scikit-learn?","p":["All ezkl requires is an onnx file and a JSON configuration of mock inputs and outputs of the neural network. At this time, it works best with PyTorch."]},{"i":"how-fast-is-ezkl","l":"How fast is ezkl?","p":["We believe that ezkl is the fastest zkml package available, and we are working hard every day to make it faster. Feel free to run cargo bench on your machine to see what the benchmarks are for your hardware."]},{"i":"do-i-need-to-deploy-a-verifier-smart-contract-to-use-ezkl","l":"Do I need to deploy a verifier smart contract to use ezkl?","p":["No, we recently integrated a WASM verifier that you can use to verify proofs from your web application. You can also use the EVM verifier to verify proofs locally, or the command line ezkl verify command."]},{"l":"Errors"},{"i":"error-verifyerror","l":"Error: VerifyError","p":["A VerifyError is thrown when the Mock prover fails, often due to a mismatched shape problem in the model. Please verify that your input.json inputs and outputs match those of your .onnx file."]},{"i":"error-dimmismatch","l":"Error: DimMismatch","p":["A DimMismatch error is thrown when there is a mismatch in the lengths of the tensor operands during circuit construction."]},{"i":"error-lookupinstantiation","l":"Error: LookupInstantiation","p":["This error is thrown when there is an error during the creation of a lookup table"]},{"i":"error-tablealreadyassigned","l":"Error: TableAlreadyAssigned","p":["A TableAlreadyAssigned Error is thrown when ezkl attempts to initialize a lookup table that has already been initialized"]},{"i":"error-unsupportedop","l":"Error: UnsupportedOp","p":["An UnsupportedOp Error is thrown when there is an operation in the ONNX file that ezkl cannot yet handle. Please look at the supported operations under src/circuit/ops to get an idea of what operations ezkl can handle."]},{"i":"error-pyvalueerror","l":"Error: PyValueError","p":["This is a pyo3 error that occurs when a data type fails to be extracted from Python to Rust. Please make sure you are passing the correct data types when utilizing the python bindings."]},{"i":"error-invalidlookupinputs","l":"Error: InvalidLookupInputs","p":["InvalidLookupInputs is thrown when the wrong inputs were passed to a lookup node."]},{"i":"error-invaliddims","l":"Error: InvalidDims","p":["InvalidDims is thrown when there is a shape mismatch in circuit construction. Invalid dimensions were used for a node with the given index and description."]},{"i":"error-wrongmethod","l":"Error: WrongMethod","p":["This error means that the wrong method was called to configure a node with the given index and description"]},{"i":"error-missingnode","l":"Error: MissingNode","p":["MissingNode is thrown when a requested node is missing in the graph with the given index"]},{"i":"error-opmismatch","l":"Error: OpMismatch","p":["OpMismatch is thrown when an unsupported method was called on a node with the given index and description"]},{"i":"error-unsupportedop-1","l":"Error: UnsupportedOp","p":["UnsupportedOp is thrown when there is an operation in the onnx graph that isn't supported by ezkl"]},{"i":"error-missingparams","l":"Error: MissingParams","p":["MissingParams is thrown when a node has missing parameters; please check the parameters in your model's operations"]},{"i":"error-misformedparams","l":"Error: MisformedParams","p":["MisformedParams is thrown when a node has misformed parameters; the error can stem from erroneous padding height and width dimensions, wrong kernel / data format, dilations that are not uint type, and more."]},{"i":"error-visibility","l":"Error: Visibility","p":["This error is typically thrown when no public variables are passed to the circuit configuration function"]},{"i":"error-nonconstantdiv","l":"Error: NonConstantDiv","p":["ezkl only supports divisions by constants"]},{"i":"error-nonconstantpower","l":"Error: NonConstantPower","p":["ezkl only supports constant exponents"]},{"i":"error-rescalingerror","l":"Error: RescalingError","p":["This error is thrown when attempting to rescale inputs for an operation"]},{"i":"error-modelload","l":"Error: ModelLoad","p":["This error is thrown when a model fails to load; please check your onnx file for missing connections / unsupported layers. We suggest using Netron to view onnx files."]}],[{"l":"Overview"},{"i":"building-a-voice-emotion-classifier-and-verifier-with-pytorch-ezkl-and-ethereum-smart-contracts","l":"Building a Voice Emotion Classifier and Verifier with PyTorch, EZKL, and Ethereum Smart Contracts","p":["This is part 1 of our tutorial on building the Cryptoidol demo app. The finished app is on Github; check out the backend and frontend."]},{"l":"Background Knowledge","p":["This article assumes prior rudimentary knowledge on the EVM, PyTorch and zero knowledge proof cryptography. If you are unfamiliar with one, a few or all of these technologies/methods (or you just want a refresher), check out the linked articles as needed."]},{"l":"Introduction","p":["In this tutorial, we will demonstrate an end-to-end flow of training a model for a specific task, creating a proof of judgement, deploying an EVM verifier, and verifying the proof of judgement using the verifier. Specifically, our task is to build a classifier that can judge voices based on their emotional content.","The voice datasets we will use are labeled using the same emotion and tone labeling standard and consist of 8 emotions: neutral, calm, happy, sad, angry, fear, disgust, surprise. The datasets are obtained from Kaggle and include the TESS, RAVDESS SONG, RAVDESS SPEECH, CREMA, and SAVEE datasets.","The code and instructions in this tutorial are provided in a Jupyter notebook which can be run in a Python environment with the necessary libraries installed."]},{"l":"Data Preparation","p":["First, we download the datasets using the Kaggle CLI and store them in a directory specified by the VOICE_DATA_DIR environment variable. We then load the datasets and create a pandas DataFrame for each. Each DataFrame includes two columns: 'Emotions', which is the label, and 'Files', which is the path to the audio file.","After loading all the datasets, we concatenate them into one DataFrame, which we will use for training our model. We also plot the distribution of emotions in our dataset using seaborn to visualize the data."]},{"l":"Training","p":["We will train a Convolutional Neural Network (CNN) model using PyTorch to classify the voice data. We choose a CNN model because we will convert all audio files into 2D frequency-domain spectrograms, which CNNs are well-suited to handle.","Our model is defined with a Conv2d layer followed by a ReLU activation function and a Linear layer. We then train the model using the Adam optimizer with a learning rate of 0.001 and a weight decay of 0.001 for regularization. We use Mean Squared Error as the loss function.","The model is trained for 10 epochs with a batch size of 10. We also split the data into training, validation, and test sets with 80%, 10%, and 10% of the data, respectively. After each epoch, we compute the validation loss to monitor the model's performance on unseen data."]},{"l":"Exporting and Verifying the Model","p":["After training the model, we export it to the ONNX format, which is a platform-agnostic format for machine learning models. We also save a sample input to a JSON file for later use.","Next, we generate a settings file for our model using the gen_settings and calibrate_settings functions from the EZKL library. We also download a Structured Reference String (SRS) which is needed for generating Zero Knowledge Proofs (ZKPs).","We then generate a witness for our model, which are the model outputs when feeding the previously saved input through the model. After that, we run a mock proof to check that all the constraints are valid.","Next, we set up the proving and verifying keys for our model and generate a full proof. We then verify the proof as a sanity check."]},{"l":"Deploying and Verifying the EVM Verifier","p":["Finally, we create an Ethereum Smart Contract that acts as a verifier for our model. We deploy the contract to a local Ethereum node using the Anvil Ethereum node simulator. After deploying the contract, we obtain its address which we will use to interact with it.","We then verify the proof using the deployed contract by calling the verify_evm function from the EZKL library and passing the proof and the contract's address. If everything is set up correctly, the proof should be verified successfully."]},{"l":"Conclusion","p":["We hope this tutorial provides a foundation for building more complex production-ready application on EZKL that require secure, verifiable judgments."]}],[{"l":"Idol Model Tutorial","p":["This is part 2 of our tutorial on building the Cryptoidol demo app; check out the backend and frontend."]},{"l":"Background Knowledge","p":["Check out these links for some useful knowledge on:","EVM,","PyTorch, and","zero knowledge proof cryptography."]},{"l":"Voice data","p":["The voice datasets we will use are labeled using the same emotion and tone labeling standard and consist of 8 emotions: neutral, calm, happy, sad, angry, fear, disgust, surprise. The datasets are obtained from Kaggle and include the TESS, RAVDESS SONG, RAVDESS SPEECH, CREMA, and SAVEE datasets.","Here we showcase a full-end-to-end flow of:","training a model for a specific task (judging voices)","creating a proof of judgment","creating and deploying an evm verifier","verifying the proof of judgment using the verifier","First we download a few voice related datasets from kaggle, which are all labelled using the same emotion and tone labelling standard.","We have 8 emotions in both speaking and singing datasets: neutral, calm, happy, sad, angry, fear, disgust, surprise.","To download the dataset make sure you have the kaggle cli installed in your local env pip install kaggle. Make sure you set up your kaggle.json file as detailed here. Then run the associated voice_data.sh data download script: sh voice_data.sh","Make sure you set the VOICE_DATA_DIR variables to point to the directory the voice_data.sh script has downloaded to. This script also accepts an argument to download to a specific directory: sh voice_data.sh /path/to/voice/data."]},{"l":"Training","p":["During training we convert all audio files into 2D frequency-domain spectrograms so that we can leverage convolutional neural networks, which tend to be more efficient than time-series model like RNNs or LSTMs. We thus:","Extract the mel spectrogram from each of the audio recordings.","Rescale each of these to the decibel (DB) scale.","Define the model as the following model:(x) - (conv) - (relu) - (linear) - (y)","You may notice that we introduce a second computational graph (key) - (key). The reasons for this are to prevent someone else from stealing your submission, and if you are not interested you can skip the following paragraph."]},{"l":"MEV prevention","p":["Let's say that obtaining a high score from the judge and then submitting said score to the EVM verifier could result in the issuance of a reward (financial or otherwise). There is an incentive then for MEV bots to scalp any issued valid proof and submit a duplicate transaction with the same proof to the verifier contract in the hopes of obtaining the reward before the original issuer. Here we add (key) - (key) such that the transaction creator's public key / address is both a private input AND a public input to the proof. As such the on-chain verification only succeeds if the key passed in during proof time is also passed in as a public input to the contract. The reward issued by the contract can then be irrevocably tied to that key such that even if the proof is submitted by another actor, the reward would STILL go to the original singer / transaction issuer.","We leverage the often-used Adam optimizer, coupled with 0.001 weight decay so as to regularize the model. The weight decay (a.k.a L2 regularization) can also help on the zk-circuit end of things in that it prevents inputs to Halo2 lookup tables from falling out of range (lookup tables are how we represent non-linearities like ReLU and Sigmoid inside our circuits).","To encode the judge’s “preferences”, we convert labels to a number between 0 and 1 where 1 is pleasantly surprised and 0 is disgust and the rest are floats in between. The model loves pleasantly surprised voices and hates disgust ;) ."]},{"l":"Exporting and Verifying the Model","p":["After training the model, we export it to the ONNX format, which is a platform-agnostic format for machine learning models. We also save a sample input to a JSON file for later use.","Next, we generate a settings file for our model using the gen_settings and calibrate_settings functions from the EZKL library. This settings file basically instantiates a bunch of parameters that determine the circuit shape, size . We use recommend also running calibrate_settings because of the way we represent nonlinearities in the circuit (using Halo2's lookup tables), it is often best to calibrate this settings file as some data can fall out of range of these lookups.","As we use Halo2 with KZG-commitments we need an SRS string from (preferably) a multi-party trusted setup ceremony. For an overview of the procedures for such a ceremony check out this page. The get_srs command retrieves a correctly sized SRS given the calibrated settings file from here.","We then generate a witness for our model, which are the model outputs when feeding the previously saved input through the model. After that, we run a mock proof to check that all the constraints are valid.","Next, we set up the proving and verifying keys for our model and generate a full proof. We then verify the proof as a sanity check.","Deploying and Verifying the EVM Verifier","Finally, we create an Ethereum Smart Contract that acts as a verifier for our model. We deploy the contract (using deploy-verifier) to a local Ethereum node using the Anvil Ethereum node simulator running on port 3030. In a separate terminal window (or using the notebook bash tooling !) run anvil -p 3030 to start the node.","After deploying the contract, we obtain its address which we will use to interact with and we can then verify the proof using the deployed contract by calling the verify_evm function from the EZKL library and passing the proof and the contract's address. If everything is set up correctly, the proof should be verified successfully!"]}],[{"l":"Idol Backend Tutorial","p":["This is part 3 of our tutorial on building the Cryptoidol demo app; check out the backend and frontend.","Setting up the proving server is very involved. Perhaps you have better things to do and would prefer a hosted service that computes proofs for your application. We now offer a managed service, ezkl hub, which takes care of all this work.","Click here to join the waiting list and try out ezkl hub."]},{"l":"Overview","p":["So you have trained the model and obtained the public key and verifier key. There’s a new problem: how are you going to serve the proofs to your users?","To do this we need a server. There are a number of ways to build a server. In this tutorial we will leverage the python bindings and use the Flask web framework because it is quick and easy to use. We’ve found that many teams using ezkl end up building their own proof server, so we decided to make a simple one part of a tutorial repo to save you time."]},{"l":"Step 1. Setting up the Flask App","p":["We are going to use poetry https://python-poetry.org/ as a way of managing our packages. If you are already familiar with npm and yarn, poetry is the equivalent in python. It has the added benefit of resolving package dependencies which ensures that you have all the compatible versions needed.","First, install poetry https://python-poetry.org/docs/. After you install poetry you can simply run","This will setup a poetry environment in the root of your repository. Follow the setup instructions provided. You can skip the dependency setup in the poetry init script for now. We will use the add command instead to install the dependencies.","There may be a need to install other system dependencies. So if the install fails, try running the following (if you are on a Debian system).","In the root of your repository, create a [app.py](http://app.py) file to set up the initial server. We’re going to keep things simple here and not use blueprints. The backend is mostly going to be a REST API server. Create a test server as such.","Access the poetry virtual environment by calling","After which you may then start the server by calling","In your browser you should be able to see the index endpoint when you navigate to the localhost: endpoint where your server is being served if you have successfully created the server.","Screenshot","Congratulations! You have just set up a basic Flask server."]},{"i":"step-2-setting-up-celery","l":"Step 2: Setting up Celery","p":["Now we need a way of proving things without blocking the server. While it is possible to use asynchronous python to achieve this, it might be better to delegate the proofs to another process entirely. One way of achieving this is with a job queue and worker processes that can pick up jobs from that job queue. The Python ecosystem has Celery which does this well.","For Celery to work, we will need Redis and RabbitMQ, Redis is a key-value database to pass results to and from various worker processes. RabbitMQ is the message passing service for the job queue. Now append to the existing app.py with the following","Now, if you try to start the server it should fail. This is because the various environment values are not set up. While you can manually run redis and rabbitmq locally, it’s much simpler to use docker for this. We will use docker compose to orchestrate this. Install docker first.","In the root of the repo, create a docker-compose.yaml file and add in the following.","We will create 4 services, web hosts the python server and serves the app via gunicorn. redis runs the redis key-value database for results, rabbitmq will be the message passing service for the queue, and worker is the celery worker that will compute proofs.","Setup a new Dockerfile in the root of the repository containing the following.","Now with that setup you should be able to build and run the server with the following commands","If it is working you should be able to navigate to your browser at 0.0.0.0:8000 now and view the default message. If not something is wrong and we will need to debug it!"]},{"i":"step-3-setting-up-the-proving-service","l":"Step 3: Setting up the proving service","p":["Now with celery setup we can create an endpoint to receive proofs. We will also need all the various artifacts. Append the following to app.py","Once this is setup you may want to restart the docker containers just to be doubly sure that new code is running.","If everything is working properly, record an audio sample of yourself or find any audio file and use the following curl command to double check if the prove endpoint is working. For example:","If the prover is working nicely you should receive the output_data and proof."]},{"i":"step-4-serving-in-production","l":"Step 4: Serving in Production","p":["You will want to secure the redis and rabbitmq by setting up credentials for them and the modifying the environment variables for them.","See the following tutorial for redis: https://nickjanetakis.com/blog/docker-tip-27-setting-a-password-on-redis-without-a-custom-config","See the following tutorial for rabbitmq: https://cloudinfrastructureservices.co.uk/create-rabbitmq-docker-container-image/","The setup will differ depending on the threat vectors, cloud providers, and how you would like to secure the backend.","We will also need ssl certificates, to do this we need an additional certbot and nginx service.","Append the following in the docker-compose.yaml file:","Now create a ./nginx folder in the root of your repository. We will create two files ./nginx/Dockerfile and ./nginx/nginx.conf. In the Dockerfile we just need to remove the default.conf nginx file to replace with our own.","Then in the ./nginx/nginx.conf we need to specify how the reverse proxy should work.","Important! You will need a domain for the ssl to work. You may purchase it from services like namecheap, google domains, godaddy, so on. You will also need to obtain a Debian or Ubuntu box to host the server.","In the ./nginx/nginx.conf add the following","You will now want to upload the entire repo to a Debian machine to host the server. You may do this with ftp or creating a git repo and cloning the repo into the server. Now in the server, run the same docker compose functions to set things up.","Check if your 443 and 80 ports are exposed via your DNS provider. We will need them exposed for the certbot challenge to obtain ssl certificates for your server. Copy the following script into your server to setup the challenge. Change the domains to the ones you have. This script was provided by this repo https://github.com/wmnnd/nginx-certbot/blob/master/init-letsencrypt.sh. You may want to set staging to 1 to perform a dry run, repeatedly spamming the script to debug can cause rate limits to be hit.","If the setup ran correctly you should now have certbot serving ssl certificates on your server. You should be able to go to your domain at [https://backend.myserver.com](https://backend.myserver.com) and see the same success message and also run proofs on [https://backend.myserver.com/prove](https://backend.myserver.com/prove)"]},{"l":"Conclusions and ezkl Hub","p":["If you have gone through all these steps you should now have a live server that is able to serve proofs!","Setting up the proving server is very involved. Perhaps you have better things to do and would prefer a hosted service that computes proofs for your application. We now offer a managed service, ezkl hub, which takes care of all this work.","Click here to join the waiting list and try out ezkl hub."]}],[{"l":"Idol Contracts Tutorial","p":["This is part 4 of our tutorial on building the Cryptoidol demo app; check out the backend and frontend.","The crypto idol contract stores the score of contestants and makes calls to the on-chain evm verifier of the corresponding ai model used to judge contestants to validate the submitted scores."]},{"i":"step-1-write-cryptoidolsol","l":"Step 1. Write CryptoIdol.sol","p":["Verifier Contract Interface: The contract leverages an external Verifier contract to verify the proof submitted by contestants. The Verifier contract interface has one function - verify- which takes public inputs and a proof as parameters and returns a boolean indicating whether the proof is valid.","Contestant Struct: The Contestant struct keeps track of a participant's score and the cycle in which they participated. A mapping associates an address (the contestant's Ethereum address) with another mapping of uint256 (the contestants entry number) to Contestant. The number of entries a given contestant has done is store in the contestantsCount mapping.","Admin: The contract has an admin address, responsible for updating the Verifier contract when a new cycle occurs. Only the admin can perform this operation. We set the admin account to the EZKL team’s multisig wallet.","Cycle: This represents the current cycle of the competition. The cycle number is incremented whenever the admin updates the Verifier contract.","3. Events","NewEntry: This event is emitted when a contestant submits their score. It logs the contestant's address, the count of their submissions, their score, and the cycle number. These events are indexed on the client-side to construct the leaderboard.","NewCycle: This event is emitted when the admin updates the Verifier contract, signalling the start of a new cycle. It logs the new Verifier's address and the updated cycle number.","4. Functions","updateVerifier: This function is used by the admin to update the Verifier contract. It increments the cycle number and emits a NewCycle event.","submitScore: Contestants use this function to submit their score and a proof. The function verifies the proof using the current Verifier contract, updates the contestant's score, and emits a NewEntry event.","5. Protection Against Miner Extractable Value (MEV)","In order to guard against MEV, the contract design includes a critical feature: the address of the account submitting their score is both a private and a public input to the proof.","Let's consider a scenario where a high score from the judge could result in a reward. There would then be an incentive for MEV bots to duplicate any issued valid proof and submit the transaction to the verifier contract, attempting to claim the reward before the original issuer.","However, with the transaction creator's public key/address being a private input AND a public input to the proof, the on-chain verification will only succeed if the key passed in during proof creation is also passed in as a public input to the contract. This design ensures that the reward issued by the contract is irrevocably tied to the original contestant's key. So even if the proof is submitted by another actor, the reward would STILL go to the original contestant, thus providing a safeguard against MEV."]},{"l":"Step 2. Deploy the contracts","p":["1. Adjust compiler settings.","As you prepare to deploy the verifier and crypto idol contracts, it is critical to set the Ethereum Virtual Machine (EVM) version to a configuration that's compatible with layer 2 blockchains. In our experience, the 'London' version has shown to be the most compatible. For the purpose of this tutorial, we'll use Remix as our deployment platform. To modify the EVM version to 'London', navigate to the 'Advanced Configurations' tab and select 'London' from the 'EVM Version' dropdown list. Neglecting to make this adjustment might result in unsuccessful deployment of your verifier Solidity code, often manifesting as a 'push0 not a valid opcode' error.","Also in cases when you are deploying an especially large verifiers and want to save on deployment costs (or just get the verifier below the max contract size limit of 24.5 kb), you will need to enable optimizations by setting the runs param to 1 to maximize deployment costs savings.","2. Deployment","You should deploy the verifier contract first, as we will need to pass the address of the verifier to the crypto idol contract’s constructor. Click the page icon next to ‘x’ on the deployed verifier instance to copy its address, then paste it into the _ verifier deploy param of CryptoIdol.sol. For the _ admin field, paste in whatever account address you want to have the ability to update the verifier contract that the crypto idol contract connects to."]},{"l":"Step 3. Create a Subgraph for the Leaderboard","p":["Creating a subgraph enables the development of a GraphQL endpoint to query the \"NewEntry\" events emitted by the contract. This data forms the basis of the CryptoIdol leaderboard, displaying the contestants with the highest submitted scores for a given cycle. By using this method, we can avoid storing the complete leaderboard on the blockchain, significantly reducing storage requirements and ensuring efficient data access."]},{"l":"Set up a Subgraph","p":["Follow these steps to create a subgraph:","Initialize a New Subgraph: Initialize a new subgraph on The Graph's hosted service. Ensure you have the Graph CLI installed and use the command graph init to start a new subgraph.","Define the Schema: Define a GraphQL schema for your subgraph. Your schema should at least include the \"NewEntry\" events, with fields for score, contestant, and cycle.","Create a Mapping: The mapping script processes the event data from the blockchain and converts it into the format defined by your schema. It's written in AssemblyScript, a variant of TypeScript. For the \"NewEntry\" event, you will need to map the score, contestant, and cycle fields.","Deploy the Subgraph: Deploy the subgraph to The Graph's hosted service using the graph deploy command."]},{"l":"Query the Subgraph","p":["Here is a sample TypeScript script that uses the created subgraph to render the leaderboard data:","This script sends a GraphQL request to the subgraph and retrieves the \"NewEntry\" events for a specific cycle. It then processes this data to generate a leaderboard, which it sorts in descending order by score."]}]]